<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/ex3.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/ex3.py" />
              <option name="originalContent" value="import numpy as np&#10;import matplotlib.pyplot as plt&#10;import cv2&#10;import mediapipe as mp&#10;from scipy.ndimage import convolve1d&#10;&#10;GAUSSIAN_VECTOR = [1, 4, 6, 4, 1]&#10;GAUSSIAN_KERNEL = np.array(GAUSSIAN_VECTOR, dtype=np.float64)&#10;REDUCE_KERNEL = GAUSSIAN_KERNEL / GAUSSIAN_KERNEL.sum()&#10;EXPAND_KERNEL = GAUSSIAN_KERNEL / (GAUSSIAN_KERNEL.sum() / 2.0)&#10;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&quot;----------- Helper functions from face_align.py and create_mask.py -----------&quot;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&#10;mp_face = mp.solutions.face_mesh&#10;FACE_OVAL_IDX = [&#10;    10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,&#10;    397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,&#10;    172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109&#10;]&#10;&#10;&#10;def build_face_mask(img, idxs=None, kernel_size=21):&#10;    if idxs is None:&#10;        idxs = FACE_OVAL_IDX&#10;&#10;    h, w = img.shape[:2]&#10;    with mp_face.FaceMesh(static_image_mode=True, max_num_faces=1,&#10;                          refine_landmarks=True) as face_mesh:&#10;        res = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))&#10;        if not res.multi_face_landmarks:&#10;            raise RuntimeError(&quot;No face detected&quot;)&#10;        lm = res.multi_face_landmarks[0].landmark&#10;        pts = np.array([[lm[i].x * w, lm[i].y * h] for i in idxs],&#10;                       dtype=np.int32)&#10;&#10;    pts = cv2.convexHull(pts)&#10;&#10;    mask = np.zeros((h, w), dtype=np.uint8)&#10;    cv2.fillPoly(mask, [pts], 1)&#10;&#10;    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,&#10;                                       (kernel_size, kernel_size))&#10;    mask = cv2.dilate(mask, kernel)&#10;    mask = (mask &gt; 0).astype(np.uint8)&#10;&#10;    return 1 - mask&#10;&#10;&#10;def get_landmarks(img):&#10;    with mp_face.FaceMesh(static_image_mode=True,&#10;                          max_num_faces=1,&#10;                          refine_landmarks=True) as face_mesh:&#10;        h, w = img.shape[:2]&#10;        results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))&#10;        if not results.multi_face_landmarks:&#10;            raise RuntimeError(&quot;No face detected&quot;)&#10;        lm = results.multi_face_landmarks[0].landmark&#10;        pts = np.array([[p.x * w, p.y * h] for p in lm], dtype=np.float32)&#10;        return pts&#10;&#10;&#10;def get_affine_keypoints(landmarks):&#10;    # use: left eye outer corner, right eye outer corner, tip of nose&#10;    idx_left_eye = 33&#10;    idx_right_eye = 263&#10;    idx_nose = 1&#10;    return np.stack([&#10;        landmarks[idx_left_eye],&#10;        landmarks[idx_right_eye],&#10;        landmarks[idx_nose],&#10;    ], axis=0)&#10;&#10;&#10;def get_shape_keypoints(landmarks, idxs=FACE_OVAL_IDX):&#10;    return np.asarray(landmarks[idxs], dtype=np.float32)&#10;&#10;&#10;def align_face(src_img, dst_img):&#10;    &quot;&quot;&quot;Align src_img to dst_img using facial landmarks.&quot;&quot;&quot;&#10;    src_landmarks = get_landmarks(src_img)&#10;    dst_landmarks = get_landmarks(dst_img)&#10;&#10;    src_shape = get_shape_keypoints(src_landmarks)&#10;    dst_shape = get_shape_keypoints(dst_landmarks)&#10;&#10;    M, _ = cv2.estimateAffinePartial2D(src_shape, dst_shape, method=cv2.LMEDS)&#10;&#10;    if M is None:&#10;        src_pts = get_affine_keypoints(src_landmarks)&#10;        dst_pts = get_affine_keypoints(dst_landmarks)&#10;        M = cv2.getAffineTransform(src_pts, dst_pts)&#10;&#10;    h, w = dst_img.shape[:2]&#10;    aligned = cv2.warpAffine(src_img, M, (w, h),&#10;                             flags=cv2.INTER_LINEAR,&#10;                             borderMode=cv2.BORDER_REFLECT_101)&#10;    return aligned&#10;&#10;&#10;def flip_lr(img):&#10;    return cv2.flip(img, 1)&#10;&#10;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&quot;---------------------------- Plotting utilities ------------------------------&quot;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&#10;def plot_image(image, title=None, out_path=None, cmap=None, show=False,&#10;               figsize=(6, 6), vmin=None, vmax=None):&#10;    &quot;&quot;&quot;&#10;    Generic helper to plot a single image and optionally save it.&#10;    Used instead of ad‑hoc matplotlib code blocks.&#10;    &quot;&quot;&quot;&#10;    img = np.asarray(image, dtype=np.float64)&#10;    if img.max() &gt; 1.0:&#10;        img = img / 255.0&#10;    if img.ndim == 2 and cmap is None:&#10;        cmap = &quot;gray&quot;&#10;&#10;    fig, ax = plt.subplots(1, 1, figsize=figsize)&#10;    ax.imshow(img, cmap=cmap, vmin=vmin, vmax=vmax)&#10;    if title is not None:&#10;        ax.set_title(title)&#10;    ax.axis(&quot;off&quot;)&#10;    plt.tight_layout()&#10;&#10;    if out_path is not None:&#10;        fig.savefig(out_path, bbox_inches=&quot;tight&quot;, pad_inches=0.1)&#10;    if show:&#10;        plt.show()&#10;&#10;    plt.close(fig)&#10;    return fig, ax&#10;&#10;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&quot;-------------------------- Task 1 - Blended Image ----------------------------&quot;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&#10;&#10;def _blur_single_channel(img, kernel):&#10;    # TODO: check results with new implementation&#10;    temp = convolve1d(img, kernel, axis=1, mode='nearest')&#10;    blurred = convolve1d(temp, kernel, axis=0, mode='nearest')&#10;    return blurred&#10;    # OLD VERSION BELOW:&#10;    # pad = len(kernel) // 2&#10;    # temp = np.zeros_like(img, dtype=np.float64)&#10;    #&#10;    # row_padded = np.pad(img, ((0, 0), (pad, pad)), mode='edge')&#10;    # for i in range(img.shape[0]):&#10;    #     temp[i, :] = np.convolve(row_padded[i], kernel, mode='valid')&#10;    #&#10;    # col_padded = np.pad(temp, ((pad, pad), (0, 0)), mode='edge')&#10;    # blurred = np.zeros_like(img, dtype=np.float64)&#10;    # for j in range(img.shape[1]):&#10;    #     blurred[:, j] = np.convolve(col_padded[:, j], kernel, mode='valid')&#10;    #&#10;    # return blurred&#10;&#10;&#10;def blur(img, kernel):&#10;    img = img.astype(np.float64, copy=False)&#10;    if img.ndim == 2:&#10;        return _blur_single_channel(img, kernel)&#10;    blurred = np.zeros_like(img)&#10;    for c in range(img.shape[2]):&#10;        blurred[..., c] = _blur_single_channel(img[..., c], kernel)&#10;    return blurred&#10;&#10;&#10;def reduce(img):&#10;    # blur and sub-sample&#10;    smoothed = blur(img, REDUCE_KERNEL)&#10;    return smoothed[::2, ::2]&#10;&#10;&#10;def expand(img):&#10;    expanded_shape = (img.shape[0] * 2, img.shape[1] * 2) + (&#10;        () if img.ndim == 2 else (img.shape[2],))&#10;    expanded_img = np.zeros(expanded_shape, dtype=np.float64)&#10;    # pad image with zeros then blur&#10;    expanded_img[::2, ::2, ...] = img&#10;    return blur(expanded_img, EXPAND_KERNEL)&#10;&#10;&#10;def gaussian_pyramid(img, num_of_levels):&#10;    &quot;&quot;&quot;Construct a Gaussian pyramid from the input image.&quot;&quot;&quot;&#10;    pyramid = [img]&#10;    current_img = img&#10;&#10;    for _ in range(1, num_of_levels):&#10;        if min(current_img.shape[:2]) &lt; 2:&#10;            break&#10;        reduced_img = reduce(current_img)&#10;        pyramid.append(reduced_img)&#10;        current_img = reduced_img&#10;&#10;    return pyramid&#10;&#10;&#10;def laplacian_pyramid(img, num_of_levels):&#10;    &quot;&quot;&quot;Construct a Laplacian pyramid from the input image.&quot;&quot;&quot;&#10;    gaussian_pyr = gaussian_pyramid(img, num_of_levels)&#10;    laplacian_pyr = []&#10;&#10;    for i in range(len(gaussian_pyr) - 1):&#10;        expanded = expand(gaussian_pyr[i + 1])&#10;        # Ensure the expanded image matches the size of the current Gaussian level&#10;        if expanded.shape != gaussian_pyr[i].shape:&#10;            target_height, target_width = gaussian_pyr[i].shape[:2]&#10;            expanded = expanded[:target_height, :target_width, ...]&#10;        laplacian_pyr.append(gaussian_pyr[i] - expanded)&#10;&#10;    # last level is the same as in Gaussian pyramid&#10;    laplacian_pyr.append(gaussian_pyr[-1])&#10;&#10;    return laplacian_pyr&#10;&#10;&#10;def load_image(img_path, as_gray=False):&#10;    img = plt.imread(img_path).astype(np.float64)&#10;    if img.max() &gt; 1.0:&#10;        img /= 255.0&#10;    if img.ndim == 3 and img.shape[2] == 4:&#10;        img = img[..., :3]&#10;    if as_gray and img.ndim == 3:&#10;        img = np.dot(img[..., :3], [0.299, 0.587, 0.114])&#10;    return img&#10;&#10;&#10;def plot_triptych(imgA, imgB, blended, titles=None, figsize=(12, 4)):&#10;    &quot;&quot;&quot;&#10;    Keep this convenience wrapper, but implement using plot_image three times.&#10;    The three images will be separate figures instead of a single triptych.&#10;    &quot;&quot;&quot;&#10;    if titles is None:&#10;        titles = (&quot;Buzzi&quot;, &quot;Bibi (Aligned)&quot;, &quot;Blended&quot;)&#10;&#10;    for image, title in zip((imgA, imgB, blended), titles):&#10;        plot_image(image, title=title, show=False)&#10;&#10;    # dummy return for backward compatibility; not really used elsewhere&#10;    return None, None&#10;&#10;&#10;def max_pyramid_levels(shape):&#10;    h, w = shape[:2]&#10;    levels = 1&#10;    while min(h, w) &gt;= 2:&#10;        h = (h + 1) // 2&#10;        w = (w + 1) // 2&#10;        levels += 1&#10;    return levels&#10;&#10;&#10;def pyramid_blending(imgA_path, imgB_path, output_path,&#10;                     mask_path='inputs/binary_mask.png'):&#10;    &quot;&quot;&quot;&#10;    • Given two inputs A and B, and a binary mask M&#10;    • Construct Laplacian Pyramids La and Lb&#10;    • Construct a Gaussian Pyramid from mask M - Gm&#10;    • Create a third Laplacian Pyramid Lc where for each level k&#10;        (, ) = (, )*(, ) + (1 − (, ))*(, )&#10;    • Sum all levels Lc in to get the blended image&#10;    &quot;&quot;&quot;&#10;    # load inputs and mask&#10;    imgA = load_image(imgA_path)&#10;    imgB = load_image(imgB_path)&#10;    mask = load_image(mask_path, as_gray=True)&#10;    mask = np.clip(mask, 0.0, 1.0)&#10;&#10;    # equalize sizes&#10;    min_shape = (min(imgA.shape[0], imgB.shape[0], mask.shape[0]),&#10;                 min(imgA.shape[1], imgB.shape[1], mask.shape[1]))&#10;    imgA = imgA[:min_shape[0], :min_shape[1], ...]&#10;    imgB = imgB[:min_shape[0], :min_shape[1], ...]&#10;    mask = mask[:min_shape[0], :min_shape[1]]&#10;&#10;    # determine number of levels&#10;    num_levels = min(max_pyramid_levels(imgA.shape),&#10;                     max_pyramid_levels(imgB.shape),&#10;                     max_pyramid_levels(mask.shape))&#10;&#10;    # create pyramids for inputs &amp; mask&#10;    La = laplacian_pyramid(imgA, num_levels)&#10;    Lb = laplacian_pyramid(imgB, num_levels)&#10;    Gm = gaussian_pyramid(mask, num_levels)&#10;&#10;    # create blended Laplacian pyramid Lc&#10;    Lc = []&#10;    for k in range(num_levels):&#10;        Lc_level = Gm[k][..., None] * La[k] + (1 - Gm[k])[..., None] * Lb[k]&#10;        Lc.append(Lc_level)&#10;&#10;    # reconstruct blended image from Lc&#10;    blended_img = Lc[-1]&#10;    for k in range(num_levels - 2, -1, -1):&#10;        blended_img = expand(blended_img)&#10;        # Ensure expanded image matches the size of current Lc level&#10;        if blended_img.shape != Lc[k].shape:&#10;            target_height, target_width = Lc[k].shape[:2]&#10;            blended_img = blended_img[:target_height, :target_width, ...]&#10;        blended_img += Lc[k]&#10;&#10;    blended_img = np.clip(blended_img, 0.0, 1.0)&#10;    plt.imsave(output_path, blended_img)&#10;    return blended_img&#10;&#10;&#10;def plot_fft_magnitude(image, out_path):&#10;    &quot;&quot;&quot;Compute log-magnitude of 2D FFT of image luminance and save as uint8 image.&quot;&quot;&quot;&#10;    img = np.array(image, dtype=np.float64, copy=False)&#10;    if img.ndim == 3 and img.shape[2] &gt;= 3:&#10;        gray = np.dot(img[..., :3], [0.299, 0.587, 0.114])&#10;    else:&#10;        gray = img if img.ndim == 2 else img[..., 0]&#10;    # ensure numeric range suitable for FFT&#10;    if gray.max() &gt; 1.0:&#10;        gray = gray / 255.0&#10;    gray = np.clip(gray, 0.0, 1.0)&#10;&#10;    F = np.fft.fft2(gray)&#10;    Fshift = np.fft.fftshift(F)&#10;    magnitude = np.log1p(np.abs(Fshift))&#10;&#10;    # normalize to [0,1]&#10;    if magnitude.max() &gt; 0:&#10;        magnitude = magnitude / magnitude.max()&#10;    else:&#10;        magnitude = np.zeros_like(magnitude)&#10;&#10;    out_uint8 = (magnitude * 255.0).round().astype(np.uint8)&#10;&#10;    plot_image(out_uint8, title=&quot;Buzzi vs. Bibi FFT Magnitude (log scale)&quot;, out_path=out_path, cmap=&quot;gray&quot;, show=False, vmin=0, vmax=255)&#10;&#10;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&quot;--------------------------- Task 2 - Hybrid Image ----------------------------&quot;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&#10;&#10;def gaussian_kernel(sigma_high, sigma_low):&#10;    &quot;&quot;&quot;&#10;    Create Gaussian kernels for high-pass and low-pass filtering.&#10;    &quot;&quot;&quot;&#10;    ksize = int(6 * sigma_low) | 1&#10;    x = np.arange(ksize) - ksize // 2&#10;    g_low = np.exp(-(x ** 2) / (2 * sigma_low ** 2))&#10;    g_low /= g_low.sum()&#10;&#10;    ksize = int(6 * sigma_high) | 1&#10;    x = np.arange(ksize) - ksize // 2&#10;    g_high = np.exp(-(x ** 2) / (2 * sigma_high ** 2))&#10;    g_high /= g_high.sum()&#10;    return g_high, g_low&#10;&#10;&#10;def hybrid_image(imgA_path, imgB_path, output_path, gray_scale=False):&#10;    &quot;&quot;&quot;&#10;    Create a hybrid image from imgA and imgB.&#10;    &quot;&quot;&quot;&#10;    # constants&#10;    LOW_SIGMA_RATIO = 0.02&#10;    HIGH_SIGMA_RATIO = 0.005&#10;&#10;    # load inputs&#10;    if gray_scale:&#10;        A = cv2.imread(imgA_path, cv2.IMREAD_GRAYSCALE) / 255.0&#10;        B = cv2.imread(imgB_path, cv2.IMREAD_GRAYSCALE) / 255.0&#10;    else:&#10;        A = load_image(imgA_path)&#10;        B = load_image(imgB_path)&#10;&#10;    # match inputs size&#10;    hA, wA = A.shape[:2]&#10;    hB, wB = B.shape[:2]&#10;    target_h = min(hA, hB)&#10;    target_w = min(wA, wB)&#10;    A = cv2.resize(A, (target_w, target_h), interpolation=cv2.INTER_AREA)&#10;    B = cv2.resize(B, (target_w, target_h), interpolation=cv2.INTER_AREA)&#10;&#10;    # calculate sigmas &amp; kernels&#10;    base = min(target_h, target_w)&#10;    sigma_low = LOW_SIGMA_RATIO * base&#10;    sigma_high = HIGH_SIGMA_RATIO * base&#10;    g_high, g_low = gaussian_kernel(sigma_high, sigma_low)&#10;&#10;    # create hybrid image&#10;    low_B = blur(B, g_low)&#10;    blurred_A = blur(A, g_high)&#10;    high_A = A - blurred_A&#10;&#10;    hybrid = low_B + high_A&#10;    hybrid = np.clip(hybrid, 0, 1)&#10;&#10;    # display and save final hybrid&#10;    plot_image(hybrid, title=None, out_path=output_path, cmap=&quot;gray&quot; if gray_scale else None, show=True, figsize=(8, 8))&#10;&#10;    return hybrid&#10;&#10;&#10;&quot;-----------------------------------------------------------------------------&quot;&#10;&quot;------------------------------ Main Execution -------------------------------&quot;&#10;&quot;-----------------------------------------------------------------------------&quot;&#10;&#10;if __name__ == '__main__':&#10;    # GOOD BLENDING PATHS&#10;    imgA_path = 'inputs/buzzi-vs-bibi/buzzi.jpeg'&#10;    imgB_path = 'inputs/buzzi-vs-bibi/bibi.jpg'&#10;    imgB_aligned_path = 'inputs/buzzi-vs-bibi/aligned.jpg'&#10;    mask_path = 'inputs/buzzi-vs-bibi/mask.jpg'&#10;&#10;    # BAD BLENDING PATHS&#10;    # imgA_path = 'inputs/eyal-vs-buzz/eyal.jpg'&#10;    # imgB_path = 'inputs/eyal-vs-buzz/bazz.jpg'&#10;    # imgB_aligned_path = 'inputs/eyal-vs-buzz/aligned.jpg'&#10;    # mask_path = 'inputs/eyal-vs-buzz/mask.jpg'&#10;&#10;    # HYBRID IMAGE PATHS&#10;    # imgA_path = 'inputs/buzzi-vs-shauli/buzzi.jpeg'&#10;    # imgB_path = 'inputs/buzzi-vs-shauli/shauli.jpg'&#10;    # imgB_aligned_path = 'inputs/buzzi-vs-shauli/aligned.jpg'&#10;    # mask_path = 'inputs/buzzi-vs-shauli/mask.jpg'&#10;&#10;    print(&quot;\nRunning...\n&quot;)&#10;&#10;    imgA_bgr = cv2.imread(imgA_path)&#10;    imgB_bgr = cv2.imread(imgB_path)&#10;    if imgA_bgr is None or imgB_bgr is None:&#10;        raise FileNotFoundError(&#10;            'Could not load source inputs for blending pipeline')&#10;&#10;    # -------------------------- Task 1 Execution ----------------------------&#10;&#10;    # create mask&#10;    mask = build_face_mask(imgA_bgr)&#10;    cv2.imwrite(mask_path, mask * 255)&#10;&#10;    # align imgB to imgA&#10;    imgB_aligned = align_face(imgB_bgr, imgA_bgr)&#10;    cv2.imwrite(imgB_aligned_path, imgB_aligned)&#10;&#10;    # execute blending&#10;    print(&quot;\nBlending inputs...\n&quot;)&#10;    blended = pyramid_blending(imgA_path, imgB_aligned_path,&#10;                               'inputs/eyal-vs-buzz/blended_ver3.jpg',&#10;                               mask_path)&#10;    plot_triptych(load_image(imgA_path), load_image(imgB_aligned_path),&#10;                  blended)&#10;    plot_fft_magnitude(blended, 'inputs/report/blended_fft_magnitude.jpg')&#10;    # -------------------------- Task 2 Execution ----------------------------&#10;&#10;    print(&quot;Creating hybrid image...&quot;)&#10;    output_path = 'outputs/results/hybrid_ver5.jpg'&#10;    hybrid_image(imgA_path, imgB_aligned_path, output_path, gray_scale=True)&#10;&#10;    print(&quot;\nDone ..!&quot;)&#10;&#10;    # TODO: create a tar file you can run the following command:&#10;    # tar -cvf ex3.tar ex3.py requirements.txt ./inputs ./outputs&#10;&#10;" />
              <option name="updatedContent" value="import numpy as np&#10;import matplotlib.pyplot as plt&#10;import cv2&#10;import mediapipe as mp&#10;from scipy.ndimage import convolve1d&#10;&#10;GAUSSIAN_VECTOR = [1, 4, 6, 4, 1]&#10;GAUSSIAN_KERNEL = np.array(GAUSSIAN_VECTOR, dtype=np.float64)&#10;REDUCE_KERNEL = GAUSSIAN_KERNEL / GAUSSIAN_KERNEL.sum()&#10;EXPAND_KERNEL = GAUSSIAN_KERNEL / (GAUSSIAN_KERNEL.sum() / 2.0)&#10;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&quot;----------- Helper functions from face_align.py and create_mask.py -----------&quot;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&#10;mp_face = mp.solutions.face_mesh&#10;FACE_OVAL_IDX = [&#10;    10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,&#10;    397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,&#10;    172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109&#10;]&#10;&#10;&#10;def build_face_mask(img, idxs=None, kernel_size=21):&#10;    if idxs is None:&#10;        idxs = FACE_OVAL_IDX&#10;&#10;    h, w = img.shape[:2]&#10;    with mp_face.FaceMesh(static_image_mode=True, max_num_faces=1,&#10;                          refine_landmarks=True) as face_mesh:&#10;        res = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))&#10;        if not res.multi_face_landmarks:&#10;            raise RuntimeError(&quot;No face detected&quot;)&#10;        lm = res.multi_face_landmarks[0].landmark&#10;        pts = np.array([[lm[i].x * w, lm[i].y * h] for i in idxs],&#10;                       dtype=np.int32)&#10;&#10;    pts = cv2.convexHull(pts)&#10;&#10;    mask = np.zeros((h, w), dtype=np.uint8)&#10;    cv2.fillPoly(mask, [pts], 1)&#10;&#10;    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,&#10;                                       (kernel_size, kernel_size))&#10;    mask = cv2.dilate(mask, kernel)&#10;    mask = (mask &gt; 0).astype(np.uint8)&#10;&#10;    return 1 - mask&#10;&#10;&#10;def get_landmarks(img):&#10;    with mp_face.FaceMesh(static_image_mode=True,&#10;                          max_num_faces=1,&#10;                          refine_landmarks=True) as face_mesh:&#10;        h, w = img.shape[:2]&#10;        results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))&#10;        if not results.multi_face_landmarks:&#10;            raise RuntimeError(&quot;No face detected&quot;)&#10;        lm = results.multi_face_landmarks[0].landmark&#10;        pts = np.array([[p.x * w, p.y * h] for p in lm], dtype=np.float32)&#10;        return pts&#10;&#10;&#10;def get_affine_keypoints(landmarks):&#10;    # use: left eye outer corner, right eye outer corner, tip of nose&#10;    idx_left_eye = 33&#10;    idx_right_eye = 263&#10;    idx_nose = 1&#10;    return np.stack([&#10;        landmarks[idx_left_eye],&#10;        landmarks[idx_right_eye],&#10;        landmarks[idx_nose],&#10;    ], axis=0)&#10;&#10;&#10;def get_shape_keypoints(landmarks, idxs=FACE_OVAL_IDX):&#10;    return np.asarray(landmarks[idxs], dtype=np.float32)&#10;&#10;&#10;def align_face(src_img, dst_img):&#10;    &quot;&quot;&quot;Align src_img to dst_img using facial landmarks.&quot;&quot;&quot;&#10;    src_landmarks = get_landmarks(src_img)&#10;    dst_landmarks = get_landmarks(dst_img)&#10;&#10;    src_shape = get_shape_keypoints(src_landmarks)&#10;    dst_shape = get_shape_keypoints(dst_landmarks)&#10;&#10;    M, _ = cv2.estimateAffinePartial2D(src_shape, dst_shape, method=cv2.LMEDS)&#10;&#10;    if M is None:&#10;        src_pts = get_affine_keypoints(src_landmarks)&#10;        dst_pts = get_affine_keypoints(dst_landmarks)&#10;        M = cv2.getAffineTransform(src_pts, dst_pts)&#10;&#10;    h, w = dst_img.shape[:2]&#10;    aligned = cv2.warpAffine(src_img, M, (w, h),&#10;                             flags=cv2.INTER_LINEAR,&#10;                             borderMode=cv2.BORDER_REFLECT_101)&#10;    return aligned&#10;&#10;&#10;def flip_lr(img):&#10;    return cv2.flip(img, 1)&#10;&#10;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&quot;---------------------------- Plotting utilities ------------------------------&quot;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&#10;def plot_image(image, title=None, out_path=None, cmap=None, show=False,&#10;               figsize=(6, 6), vmin=None, vmax=None):&#10;    &quot;&quot;&quot;&#10;    Generic helper to plot a single image and optionally save it.&#10;    Used instead of ad‑hoc matplotlib code blocks.&#10;    &quot;&quot;&quot;&#10;    img = np.asarray(image, dtype=np.float64)&#10;    if img.max() &gt; 1.0:&#10;        img = img / 255.0&#10;    if img.ndim == 2 and cmap is None:&#10;        cmap = &quot;gray&quot;&#10;&#10;    fig, ax = plt.subplots(1, 1, figsize=figsize)&#10;    ax.imshow(img, cmap=cmap, vmin=vmin, vmax=vmax)&#10;    if title is not None:&#10;        ax.set_title(title)&#10;    ax.axis(&quot;off&quot;)&#10;    plt.tight_layout()&#10;&#10;    if out_path is not None:&#10;        fig.savefig(out_path, bbox_inches=&quot;tight&quot;, pad_inches=0.1)&#10;    if show:&#10;        plt.show()&#10;&#10;    plt.close(fig)&#10;    return fig, ax&#10;&#10;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&quot;-------------------------- Task 1 - Blended Image ----------------------------&quot;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&#10;&#10;def _blur_single_channel(img, kernel):&#10;    # TODO: check results with new implementation&#10;    temp = convolve1d(img, kernel, axis=1, mode='nearest')&#10;    blurred = convolve1d(temp, kernel, axis=0, mode='nearest')&#10;    return blurred&#10;    # OLD VERSION BELOW:&#10;    # pad = len(kernel) // 2&#10;    # temp = np.zeros_like(img, dtype=np.float64)&#10;    #&#10;    # row_padded = np.pad(img, ((0, 0), (pad, pad)), mode='edge')&#10;    # for i in range(img.shape[0]):&#10;    #     temp[i, :] = np.convolve(row_padded[i], kernel, mode='valid')&#10;    #&#10;    # col_padded = np.pad(temp, ((pad, pad), (0, 0)), mode='edge')&#10;    # blurred = np.zeros_like(img, dtype=np.float64)&#10;    # for j in range(img.shape[1]):&#10;    #     blurred[:, j] = np.convolve(col_padded[:, j], kernel, mode='valid')&#10;    #&#10;    # return blurred&#10;&#10;&#10;def blur(img, kernel):&#10;    img = img.astype(np.float64, copy=False)&#10;    if img.ndim == 2:&#10;        return _blur_single_channel(img, kernel)&#10;    blurred = np.zeros_like(img)&#10;    for c in range(img.shape[2]):&#10;        blurred[..., c] = _blur_single_channel(img[..., c], kernel)&#10;    return blurred&#10;&#10;&#10;def reduce(img):&#10;    # blur and sub-sample&#10;    smoothed = blur(img, REDUCE_KERNEL)&#10;    return smoothed[::2, ::2]&#10;&#10;&#10;def expand(img):&#10;    expanded_shape = (img.shape[0] * 2, img.shape[1] * 2) + (&#10;        () if img.ndim == 2 else (img.shape[2],))&#10;    expanded_img = np.zeros(expanded_shape, dtype=np.float64)&#10;    # pad image with zeros then blur&#10;    expanded_img[::2, ::2, ...] = img&#10;    return blur(expanded_img, EXPAND_KERNEL)&#10;&#10;&#10;def gaussian_pyramid(img, num_of_levels):&#10;    &quot;&quot;&quot;Construct a Gaussian pyramid from the input image.&quot;&quot;&quot;&#10;    pyramid = [img]&#10;    current_img = img&#10;&#10;    for _ in range(1, num_of_levels):&#10;        if min(current_img.shape[:2]) &lt; 2:&#10;            break&#10;        reduced_img = reduce(current_img)&#10;        pyramid.append(reduced_img)&#10;        current_img = reduced_img&#10;&#10;    return pyramid&#10;&#10;&#10;def laplacian_pyramid(img, num_of_levels):&#10;    &quot;&quot;&quot;Construct a Laplacian pyramid from the input image.&quot;&quot;&quot;&#10;    gaussian_pyr = gaussian_pyramid(img, num_of_levels)&#10;    laplacian_pyr = []&#10;&#10;    for i in range(len(gaussian_pyr) - 1):&#10;        expanded = expand(gaussian_pyr[i + 1])&#10;        # Ensure the expanded image matches the size of the current Gaussian level&#10;        if expanded.shape != gaussian_pyr[i].shape:&#10;            target_height, target_width = gaussian_pyr[i].shape[:2]&#10;            expanded = expanded[:target_height, :target_width, ...]&#10;        laplacian_pyr.append(gaussian_pyr[i] - expanded)&#10;&#10;    # last level is the same as in Gaussian pyramid&#10;    laplacian_pyr.append(gaussian_pyr[-1])&#10;&#10;    return laplacian_pyr&#10;&#10;&#10;def load_image(img_path, as_gray=False):&#10;    img = plt.imread(img_path).astype(np.float64)&#10;    if img.max() &gt; 1.0:&#10;        img /= 255.0&#10;    if img.ndim == 3 and img.shape[2] == 4:&#10;        img = img[..., :3]&#10;    if as_gray and img.ndim == 3:&#10;        img = np.dot(img[..., :3], [0.299, 0.587, 0.114])&#10;    return img&#10;&#10;&#10;def plot_triptych(imgA, imgB, blended, titles=None, figsize=(12, 4)):&#10;    &quot;&quot;&quot;&#10;    Keep this convenience wrapper, but implement using plot_image three times.&#10;    The three images will be separate figures instead of a single triptych.&#10;    &quot;&quot;&quot;&#10;    if titles is None:&#10;        titles = (&quot;Buzzi&quot;, &quot;Bibi (Aligned)&quot;, &quot;Blended&quot;)&#10;&#10;    for image, title in zip((imgA, imgB, blended), titles):&#10;        plot_image(image, title=title, show=False)&#10;&#10;    # dummy return for backward compatibility; not really used elsewhere&#10;    return None, None&#10;&#10;&#10;def max_pyramid_levels(shape):&#10;    h, w = shape[:2]&#10;    levels = 1&#10;    while min(h, w) &gt;= 2:&#10;        h = (h + 1) // 2&#10;        w = (w + 1) // 2&#10;        levels += 1&#10;    return levels&#10;&#10;&#10;def pyramid_blending(imgA_path, imgB_path, output_path,&#10;                     mask_path='inputs/binary_mask.png'):&#10;    &quot;&quot;&quot;&#10;    • Given two inputs A and B, and a binary mask M&#10;    • Construct Laplacian Pyramids La and Lb&#10;    • Construct a Gaussian Pyramid from mask M - Gm&#10;    • Create a third Laplacian Pyramid Lc where for each level k&#10;        (, ) = (, )*(, ) + (1 − (, ))*(, )&#10;    • Sum all levels Lc in to get the blended image&#10;    &quot;&quot;&quot;&#10;    # load inputs and mask&#10;    imgA = load_image(imgA_path)&#10;    imgB = load_image(imgB_path)&#10;    mask = load_image(mask_path, as_gray=True)&#10;    mask = np.clip(mask, 0.0, 1.0)&#10;&#10;    # equalize sizes&#10;    min_shape = (min(imgA.shape[0], imgB.shape[0], mask.shape[0]),&#10;                 min(imgA.shape[1], imgB.shape[1], mask.shape[1]))&#10;    imgA = imgA[:min_shape[0], :min_shape[1], ...]&#10;    imgB = imgB[:min_shape[0], :min_shape[1], ...]&#10;    mask = mask[:min_shape[0], :min_shape[1]]&#10;&#10;    # determine number of levels&#10;    num_levels = min(max_pyramid_levels(imgA.shape),&#10;                     max_pyramid_levels(imgB.shape),&#10;                     max_pyramid_levels(mask.shape))&#10;&#10;    # create pyramids for inputs &amp; mask&#10;    La = laplacian_pyramid(imgA, num_levels)&#10;    Lb = laplacian_pyramid(imgB, num_levels)&#10;    Gm = gaussian_pyramid(mask, num_levels)&#10;&#10;    # create blended Laplacian pyramid Lc&#10;    Lc = []&#10;    for k in range(num_levels):&#10;        Lc_level = Gm[k][..., None] * La[k] + (1 - Gm[k])[..., None] * Lb[k]&#10;        Lc.append(Lc_level)&#10;&#10;    # reconstruct blended image from Lc&#10;    blended_img = Lc[-1]&#10;    for k in range(num_levels - 2, -1, -1):&#10;        blended_img = expand(blended_img)&#10;        # Ensure expanded image matches the size of current Lc level&#10;        if blended_img.shape != Lc[k].shape:&#10;            target_height, target_width = Lc[k].shape[:2]&#10;            blended_img = blended_img[:target_height, :target_width, ...]&#10;        blended_img += Lc[k]&#10;&#10;    blended_img = np.clip(blended_img, 0.0, 1.0)&#10;    plt.imsave(output_path, blended_img)&#10;    return blended_img&#10;&#10;&#10;def plot_fft_magnitude(image, out_path):&#10;    &quot;&quot;&quot;Compute log-magnitude of 2D FFT of image luminance and save as uint8 image.&quot;&quot;&quot;&#10;    img = np.array(image, dtype=np.float64, copy=False)&#10;    if img.ndim == 3 and img.shape[2] &gt;= 3:&#10;        gray = np.dot(img[..., :3], [0.299, 0.587, 0.114])&#10;    else:&#10;        gray = img if img.ndim == 2 else img[..., 0]&#10;    # ensure numeric range suitable for FFT&#10;    if gray.max() &gt; 1.0:&#10;        gray = gray / 255.0&#10;    gray = np.clip(gray, 0.0, 1.0)&#10;&#10;    F = np.fft.fft2(gray)&#10;    Fshift = np.fft.fftshift(F)&#10;    magnitude = np.log1p(np.abs(Fshift))&#10;&#10;    # normalize to [0,1]&#10;    if magnitude.max() &gt; 0:&#10;        magnitude = magnitude / magnitude.max()&#10;    else:&#10;        magnitude = np.zeros_like(magnitude)&#10;&#10;    out_uint8 = (magnitude * 255.0).round().astype(np.uint8)&#10;&#10;    plot_image(out_uint8, title=&quot;Buzzi vs. Bibi FFT Magnitude (log scale)&quot;, out_path=out_path, cmap=&quot;gray&quot;, show=False, vmin=0, vmax=255)&#10;&#10;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&quot;--------------------------- Task 2 - Hybrid Image ----------------------------&quot;&#10;&quot;------------------------------------------------------------------------------&quot;&#10;&#10;&#10;def gaussian_kernel(sigma_high, sigma_low):&#10;    &quot;&quot;&quot;&#10;    Create Gaussian kernels for high-pass and low-pass filtering.&#10;    &quot;&quot;&quot;&#10;    ksize = int(6 * sigma_low) | 1&#10;    x = np.arange(ksize) - ksize // 2&#10;    g_low = np.exp(-(x ** 2) / (2 * sigma_low ** 2))&#10;    g_low /= g_low.sum()&#10;&#10;    ksize = int(6 * sigma_high) | 1&#10;    x = np.arange(ksize) - ksize // 2&#10;    g_high = np.exp(-(x ** 2) / (2 * sigma_high ** 2))&#10;    g_high /= g_high.sum()&#10;    return g_high, g_low&#10;&#10;&#10;def hybrid_image(imgA_path, imgB_path, output_path, gray_scale=False):&#10;    &quot;&quot;&quot;&#10;    Create a hybrid image from imgA and imgB.&#10;    &quot;&quot;&quot;&#10;    # constants&#10;    LOW_SIGMA_RATIO = 0.02&#10;    HIGH_SIGMA_RATIO = 0.005&#10;&#10;    # load inputs&#10;    if gray_scale:&#10;        A = cv2.imread(imgA_path, cv2.IMREAD_GRAYSCALE) / 255.0&#10;        B = cv2.imread(imgB_path, cv2.IMREAD_GRAYSCALE) / 255.0&#10;    else:&#10;        A = load_image(imgA_path)&#10;        B = load_image(imgB_path)&#10;&#10;    # match inputs size&#10;    hA, wA = A.shape[:2]&#10;    hB, wB = B.shape[:2]&#10;    target_h = min(hA, hB)&#10;    target_w = min(wA, wB)&#10;    A = cv2.resize(A, (target_w, target_h), interpolation=cv2.INTER_AREA)&#10;    B = cv2.resize(B, (target_w, target_h), interpolation=cv2.INTER_AREA)&#10;&#10;    # calculate sigmas &amp; kernels&#10;    base = min(target_h, target_w)&#10;    sigma_low = LOW_SIGMA_RATIO * base&#10;    sigma_high = HIGH_SIGMA_RATIO * base&#10;    g_high, g_low = gaussian_kernel(sigma_high, sigma_low)&#10;&#10;    # create hybrid image&#10;    low_B = blur(B, g_low)&#10;    blurred_A = blur(A, g_high)&#10;    high_A = A - blurred_A&#10;&#10;    hybrid = low_B + high_A&#10;    hybrid = np.clip(hybrid, 0, 1)&#10;&#10;    # display and save final hybrid&#10;    plot_image(hybrid, title=None, out_path=output_path, cmap=&quot;gray&quot; if gray_scale else None, show=True, figsize=(8, 8))&#10;&#10;    return hybrid&#10;&#10;&#10;&quot;-----------------------------------------------------------------------------&quot;&#10;&quot;------------------------------ Main Execution -------------------------------&quot;&#10;&quot;-----------------------------------------------------------------------------&quot;&#10;&#10;if __name__ == '__main__':&#10;    # GOOD BLENDING PATHS&#10;    imgA_path = 'inputs/buzzi-vs-bibi/buzzi.jpeg'&#10;    imgB_path = 'inputs/buzzi-vs-bibi/bibi.jpg'&#10;    imgB_aligned_path = 'inputs/buzzi-vs-bibi/aligned.jpg'&#10;    mask_path = 'inputs/buzzi-vs-bibi/mask.jpg'&#10;&#10;    # BAD BLENDING PATHS&#10;    # imgA_path = 'inputs/eyal-vs-buzz/eyal.jpg'&#10;    # imgB_path = 'inputs/eyal-vs-buzz/bazz.jpg'&#10;    # imgB_aligned_path = 'inputs/eyal-vs-buzz/aligned.jpg'&#10;    # mask_path = 'inputs/eyal-vs-buzz/mask.jpg'&#10;&#10;    # HYBRID IMAGE PATHS&#10;    # imgA_path = 'inputs/buzzi-vs-shauli/buzzi.jpeg'&#10;    # imgB_path = 'inputs/buzzi-vs-shauli/shauli.jpg'&#10;    # imgB_aligned_path = 'inputs/buzzi-vs-shauli/aligned.jpg'&#10;    # mask_path = 'inputs/buzzi-vs-shauli/mask.jpg'&#10;&#10;    print(&quot;\nRunning...\n&quot;)&#10;&#10;    imgA_bgr = cv2.imread(imgA_path)&#10;    imgB_bgr = cv2.imread(imgB_path)&#10;    if imgA_bgr is None or imgB_bgr is None:&#10;        raise FileNotFoundError(&#10;            'Could not load source inputs for blending pipeline')&#10;&#10;    # -------------------------- Task 1 Execution ----------------------------&#10;&#10;    # create mask&#10;    mask = build_face_mask(imgA_bgr)&#10;    cv2.imwrite(mask_path, mask * 255)&#10;&#10;    # align imgB to imgA&#10;    imgB_aligned = align_face(imgB_bgr, imgA_bgr)&#10;    cv2.imwrite(imgB_aligned_path, imgB_aligned)&#10;&#10;    # execute blending&#10;    print(&quot;\nBlending inputs...\n&quot;)&#10;    blended = pyramid_blending(imgA_path, imgB_aligned_path,&#10;                               'inputs/eyal-vs-buzz/blended_ver3.jpg',&#10;                               mask_path)&#10;    plot_triptych(load_image(imgA_path), load_image(imgB_aligned_path),&#10;                  blended)&#10;    plot_fft_magnitude(blended, 'inputs/report/blended_fft_magnitude.jpg')&#10;    # -------------------------- Task 2 Execution ----------------------------&#10;&#10;    print(&quot;Creating hybrid image...&quot;)&#10;    output_path = 'outputs/results/hybrid_ver5.jpg'&#10;    hybrid_image(imgA_path, imgB_aligned_path, output_path, gray_scale=True)&#10;&#10;    print(&quot;\nDone ..!&quot;)&#10;&#10;    # TODO: create a tar file you can run the following command:&#10;    # tar -cvf ex3.tar ex3.py requirements.txt ./inputs ./outputs&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>